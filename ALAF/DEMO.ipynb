{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22091410",
      "metadata": {
        "id": "22091410"
      },
      "source": [
        "# Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad74086",
      "metadata": {
        "id": "aad74086"
      },
      "outputs": [],
      "source": [
        "import collections.abc\n",
        "import collections\n",
        "import cv2\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import pycocotools\n",
        "import pylab\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import time as time\n",
        "import wget\n",
        "import zipfile\n",
        "\n",
        "from cv2 import dnn_superres\n",
        "from dict2xml import dict2xml\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from time import time\n",
        "\n",
        "from Cluster import *\n",
        "from ALAF import *\n",
        "from Utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33de1471",
      "metadata": {
        "id": "33de1471"
      },
      "outputs": [],
      "source": [
        "#PLEASE DEFINE WHERE DO YOU WANT TO CREATE THE FOLDER TO SAVE THE OUTPUTS PROVIDE BY OUR PROPOSAL\n",
        "OUTPUT_DIR = ''\n",
        "create_dir(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1899bdd",
      "metadata": {
        "id": "e1899bdd"
      },
      "source": [
        "# Download Super-Resolution Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88c5084c",
      "metadata": {
        "id": "88c5084c"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'FSRCNN_x2'\n",
        "MODEL_SR_DIR = OUTPUT_DIR+'MODEL_SR'\n",
        "create_dir(MODEL_SR_DIR)\n",
        "PATH_TO_MODEL_DIR = download_model_SR(MODEL_NAME, MODEL_SR_DIR+'/FSRCNN_x2.pb')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95da7587",
      "metadata": {
        "id": "95da7587"
      },
      "source": [
        "# Download Object Detection Model - EfficientDet D4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922ff8e9",
      "metadata": {
        "id": "922ff8e9"
      },
      "outputs": [],
      "source": [
        "MODEL_DATE = '20200711'\n",
        "MODEL_NAME = 'efficientdet_d4_coco17_tpu-32'\n",
        "PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "717c78fd",
      "metadata": {
        "id": "717c78fd"
      },
      "source": [
        "# Download the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1666cb",
      "metadata": {
        "id": "ca1666cb"
      },
      "outputs": [],
      "source": [
        "LABEL_FILENAME = 'mscoco_complete_label_map.pbtxt'\n",
        "PATH_TO_LABELS = download_labels(LABEL_FILENAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45505583",
      "metadata": {
        "id": "45505583"
      },
      "source": [
        "# Loading the Object Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19de938",
      "metadata": {
        "id": "d19de938"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b4d37c",
      "metadata": {
        "id": "80b4d37c"
      },
      "source": [
        "# Loading Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb6d61c",
      "metadata": {
        "id": "fdb6d61c"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dac3ff0b",
      "metadata": {
        "id": "dac3ff0b"
      },
      "source": [
        "# Start Our Proposal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd09394",
      "metadata": {
        "id": "8dd09394"
      },
      "outputs": [],
      "source": [
        "matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a22273e",
      "metadata": {
        "id": "6a22273e"
      },
      "outputs": [],
      "source": [
        "dict_COCO_names = {\n",
        "    1:\"person\", 2:\"bicycle\", 3:\"car\", 4:\"motorcycle\", 5:\"airplane\", 6:\"bus\", 7:\"train\", 8:\"truck\", 9:\"boat\", 10:\"traffic light\", 11:\"fire hydrant\", 12:\"street sign\", 13:\"stop sign\", 14:\"parking meter\", 15:\"bench\", 16:\"bird\", 17:\"cat\", 18:\"dog\", 19:\"horse\", 20:\"sheep\", 21:\"cow\", 22:\"elephant\", 23:\"bear\", 24:\"zebra\", 25:\"giraffe\", 26:\"hat\", 27:\"backpack\", 28:\"umbrella\", 29:\"shoe\", 30:\"eye glasses\", 31:\"handbag\", 32:\"tie\", 33:\"suitcase\", 34:\"frisbee\", 35:\"skis\", 36:\"snowboard\", 37:\"sports ball\", 38:\"kite\", 39:\"baseball bat\", 40:\"baseball glove\", 41:\"skateboard\", 42:\"surfboard\", 43:\"tennis racket\", 44:\"bottle\", 45:\"plate\", 46:\"wine glass\", 47:\"cup\", 48:\"fork\", 49:\"knife\", 50:\"spoon\", 51:\"bowl\", 52:\"banana\", 53:\"apple\", 54:\"sandwich\", 55:\"orange\", 56:\"broccoli\", 57:\"carrot\", 58:\"hot dog\", 59:\"pizza\", 60:\"donut\", 61:\"cake\", 62:\"chair\", 63:\"couch\", 64:\"potted plant\", 65:\"bed\", 66:\"mirror\", 67:\"dining table\", 68:\"window\", 69:\"desk\", 70:\"toilet\", 71:\"door\", 72:\"tv\", 73:\"laptop\", 74:\"mouse\", 75:\"remote\", 76:\"keyboard\", 77:\"cell phone\", 78:\"microwave\", 79:\"oven\", 80:\"toaster\", 81:\"sink\", 82:\"refrigerator\", 83:\"blender\", 84:\"book\", 85:\"clock\", 86:\"vase\", 87:\"scissors\", 88:\"teddy bear\", 89:\"hair drier\", 90:\"toothbrush\", 91:\"hair brush\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd6e212",
      "metadata": {
        "id": "2fd6e212"
      },
      "source": [
        "# Test Our Proposal Without Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7186a328",
      "metadata": {
        "id": "7186a328"
      },
      "outputs": [],
      "source": [
        "#Arguments: make_inference_SRSR(model_loaded,category_index,path_image_infer,name_image,path_save_image_with_detections,clases_to_detect,min_score_detect_element,path_model_sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb849ace",
      "metadata": {
        "id": "fb849ace"
      },
      "outputs": [],
      "source": [
        "make_inference_SRSR(detect_fn,category_index,'/opt/share/Github/TEST/0.jpg','OUT.jpg','/opt/share/Github/TEST/PRUEBA',[3],0.35,'/opt/share/Github/TEST/MODEL_SR/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ba1e85c",
      "metadata": {
        "scrolled": true,
        "id": "2ba1e85c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "#PLEASE INSERT THE PATH OF THE FOLDER THAT CONTAINS THE IMAGES TO TRAIN\n",
        "imagenes_dir_train = ''\n",
        "\n",
        "#PLEASE INSERT THE CLASSES (COCO) THAT YOU WANT TO DETECT FOR EXAMPLE, IF YOU WANT TO DETECT ONLY CARS [3]\n",
        "CLASES = []\n",
        "\n",
        "MODEL = 'OUTPUT'\n",
        "\n",
        "unlabeled_dataset = os.listdir(imagenes_dir_train)\n",
        "\n",
        "create_dir(OUTPUT_DIR+MODEL)\n",
        "create_dir(OUTPUT_DIR+MODEL+'/FACTOR-OPT/AUX/')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/json/')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/json/train')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/json/validation')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/xml/')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/xml/train')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/xml/validation')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/AUX/')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/FT/')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/FT/MODEL')\n",
        "create_dir(OUTPUT_DIR+MODEL+'/FT/EXPORT')\n",
        "\n",
        "counter = 0\n",
        "PATH_AUX = OUTPUT_DIR+MODEL+'/AUX/'\n",
        "\n",
        "'''SPLITTING OF IMAGES FOR TRAINING AND VALIDATION'''\n",
        "Number_Images_Split = int(len(unlabeled_dataset) * 15 / 100)\n",
        "limite = int(len(unlabeled_dataset)-Number_Images_Split)\n",
        "counter_split = 0\n",
        "    \n",
        "for frame in unlabeled_dataset:\n",
        "   \n",
        "  if int(counter_split) < limite:\n",
        "    frame_path_copy = OUTPUT_DIR+MODEL+'/xml/train'+\"/{}\".format(frame)\n",
        "    json_dir = OUTPUT_DIR+MODEL+'/json/train'+'/'\n",
        "    xml_dir = OUTPUT_DIR+MODEL+'/xml/train'+'/'\n",
        "  else:\n",
        "    frame_path_copy = OUTPUT_DIR+MODEL+'/xml/validation'+\"/{}\".format(frame)\n",
        "    json_dir = OUTPUT_DIR+MODEL+'/json/validation'+'/'\n",
        "    xml_dir = OUTPUT_DIR+MODEL+'/xml/validation'+'/'\n",
        "     \n",
        "  counter_split = counter_split + 1\n",
        "  \n",
        "  folder_save_detections = OUTPUT_DIR+MODEL+'/FACTOR-OPT/'\n",
        "  image_path_normal = imagenes_dir_train+str(frame)\n",
        "  shutil.copyfile(image_path_normal, frame_path_copy)\n",
        "  \n",
        "  output = make_inference_SRSR(detect_fn,category_index,frame_path_copy,frame,folder_save_detections,CLASES,0.25, MODEL_SR_DIR+'/')\n",
        "  counter = counter+1\n",
        "\n",
        "  clases = output[2]\n",
        "  width = output[3]\n",
        "  height = output[4]\n",
        "\n",
        "  id = frame.replace('.jpg','')\n",
        "\n",
        "  x = '{\"annotation\":{\"folder\": \"images\",\"filename\": \"1.jpg\",\"path\": \"/ALAF/images/1.jpg\",\"source\": {\"database\": \"Unknown\"},\"size\": {\"width\": \"0\",\"height\": \"0\",\"depth\": \"3\"},\"segmented\": \"0\",\"object\": []}}'\n",
        "  y = json.loads(x)\n",
        "  y[\"annotation\"][\"folder\"] = 'IMAGENES'\n",
        "  y[\"annotation\"][\"filename\"] = frame\n",
        "  y[\"annotation\"][\"path\"] = frame_path_copy\n",
        "  y[\"annotation\"][\"size\"][\"width\"] = width\n",
        "  y[\"annotation\"][\"size\"][\"height\"] = height\n",
        "\n",
        "  boxes2 = []\n",
        "    \n",
        "  for id_class, box in enumerate(output[0]):\n",
        "    ymin = int(box[0]*height)\n",
        "    xmin = int(box[1]*width)\n",
        "    ymax = int(box[2]*height)\n",
        "    xmax = int(box[3]*width) \n",
        "\n",
        "    objeto1 = '{\"name\": \"car\",\"pose\": \"Unspecified\",\"truncated\": \"0\",\"difficult\": \"0\",\"bndbox\": {\"xmin\": \"302\",\"ymin\": \"215\",\"xmax\": \"338\",\"ymax\": \"237\"}}'\n",
        "    z = json.loads(objeto1)\n",
        "    \n",
        "    z[\"name\"] = str(dict_COCO_names[clases[id_class]])\n",
        "    z[\"bndbox\"][\"xmin\"] = xmin \n",
        "    z[\"bndbox\"][\"xmax\"] = xmax\n",
        "    z[\"bndbox\"][\"ymin\"] = ymin\n",
        "    z[\"bndbox\"][\"ymax\"] = ymax\n",
        "    y['annotation']['object'].append(z)\n",
        "    \n",
        "  json_file_path  = json_dir+id+'.json'\n",
        "  xml_file_path   = xml_dir+id+'.xml'\n",
        "  \n",
        "  with open(json_file_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(y, f)\n",
        "\n",
        "  if len(output[0]) > 0:\n",
        "      with open(json_file_path) as json_file:\n",
        "        data = json.load(json_file)\n",
        "        xml = dict2xml(data)\n",
        "        with open(xml_file_path, \"w\") as f:\n",
        "          f.write(xml)\n",
        "  else:\n",
        "    os.remove(frame_path_copy)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85dcf2e5",
      "metadata": {
        "id": "85dcf2e5"
      },
      "outputs": [],
      "source": [
        "!python /opt/share/DATA/generate_tfrecord.py -x OUTPUT_DIR+MODELO+'/xml/train/' -l /opt/share/DATA/REENTRENOSM2/label_map.pbtxt -o OUTPUT_DIR+MODELO+'/xml/train/trainOK.record'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f854d696",
      "metadata": {
        "id": "f854d696"
      },
      "outputs": [],
      "source": [
        "!python /opt/share/DATA/generate_tfrecord.py -x OUTPUT_DIR+MODELO+'/xml/validation/' -l /opt/share/DATA/REENTRENOSM2/label_map3.pbtxt -o OUTPUT_DIR+MODELO+'/xml/validation/validationOK.record'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2470314c",
      "metadata": {
        "id": "2470314c"
      },
      "outputs": [],
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d4_coco17_tpu-32.tar.gz\n",
        "!tar xvzf efficientdet_d4_coco17_tpu-32.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "934cad4e",
      "metadata": {
        "scrolled": true,
        "id": "934cad4e"
      },
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python /home/ivangarcia/Desktop/PRL/DATA/model_main_tf2.py --model_dir=/home/ivangarcia/Desktop/PRL/MODELOS/PRUEBASVIDEO2/2/MODELORE/ --pipeline_config_path=/home/ivangarcia/Desktop/PRL/MODELOS/PRUEBASVIDEO2/2/ED4.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "546cbf0d",
      "metadata": {
        "scrolled": true,
        "id": "546cbf0d"
      },
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python /home/ivangarcia/Desktop/PRL/DATA/exporter_main_v2.py --input_type image_tensor --pipeline_config_path /home/ivangarcia/Desktop/PRL/MODELOS/PRUEBASVIDEO2/1/ED4.config --trained_checkpoint_dir /home/ivangarcia/Desktop/PRL/MODELOS/PRUEBASVIDEO2/1/EXP/ --output_directory /home/ivangarcia/Desktop/PRL/MODELOS/PRUEBASVIDEO2/1/SV/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36908124",
      "metadata": {
        "id": "36908124"
      },
      "source": [
        "# EVALUATION OF THE RE-TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7ba4db",
      "metadata": {
        "id": "cc7ba4db"
      },
      "outputs": [],
      "source": [
        "#PLEASE INSERT THE PATH OF THE FINE-TUNED MODEL\n",
        "PATH_TO_MODEL_DIR = OUTPUT_DIR+MODEL+'/FT/EXPORT/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cecb8b54",
      "metadata": {
        "id": "cecb8b54"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3f4c47",
      "metadata": {
        "id": "ce3f4c47"
      },
      "source": [
        "# LOAD THE JSON WITH THE GT ANNOTATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3403786b",
      "metadata": {
        "id": "3403786b"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "jsonString = ''\n",
        "\n",
        "diccionario_ids = {}\n",
        "\n",
        "with open(jsonString) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for p3 in data['images']:\n",
        "        data_s_image = p3['file_name'].replace('images/','')\n",
        "        data_s_id = p3['id']\n",
        "        diccionario_ids[data_s_image] = data_s_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd6f15e",
      "metadata": {
        "id": "4cd6f15e"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "#PLEASE INSERT THE PATH OF THE FOLDER THAT CONTAINS THE IMAGES TO TEST THE FINE-TUNED MODEL\n",
        "imagenes_dir_train = ''\n",
        "\n",
        "#PLEASE INSERT THE PATH TO GENERATE THE OUTPUTS\n",
        "PATH_EVAL = ''\n",
        "\n",
        "#PLEASE INSERT THE CLASSES (COCO) THAT YOU WANT TO DETECT\n",
        "CLASES = []\n",
        "\n",
        "#PLEASE INSERT THE MINIMUN SCORE TO DETECT ONE OBJECT\n",
        "SCORE = 0.35\n",
        "\n",
        "MODEL = 'OUTPUT-EVAL'\n",
        "\n",
        "test_dataset = os.listdir(imagenes_dir_train)\n",
        "\n",
        "create_dir(PATH_EVAL+MODEL)\n",
        "create_dir(PATH_EVAL+MODEL+'/FACTOR-OPT/SALIDA/')\n",
        "create_dir(PATH_EVAL+MODEL+'/AUX/')\n",
        "create_dir(PATH_EVAL+MODEL+'/JSON/')\n",
        "PATH_AUX = PATH_EVAL+MODEL+'/AUX/'\n",
        "\n",
        "imagenes_dir3 = imagenes_dir_train\n",
        "frames_test = os.listdir(imagenes_dir_train)\n",
        "imagenes_dir2 = []\n",
        "counter = 0\n",
        "\n",
        "result = []\n",
        "result2 = []\n",
        "out = []\n",
        "out2 = []\n",
        "\n",
        "\n",
        "for frame in frames_test:\n",
        "  \n",
        "  id = frame.replace('.jpg','')\n",
        "  image_path_save = imagenes_dir_train+\"/\"+str(frame)\n",
        "  \n",
        "  output = make_inference_SRSRRAW(detect_fn,category_index,image_path_save,frame,PATH_EVAL+MODEL+'/AUX/',CLASES,SCORE)\n",
        "\n",
        "  counter = counter+1\n",
        "    \n",
        "  result = []\n",
        "  result2 = []\n",
        "  out2= []\n",
        "    \n",
        "  '''GET THE ID FOR EACH FRAME'''\n",
        "  converted_num = diccionario_ids[frame]\n",
        "    \n",
        "  width = output[3]\n",
        "  height = output[4]\n",
        "  boxes2 = []\n",
        "\n",
        "\n",
        "  '''TRANSLATE THE COORDINATES WITH COCO FORMAT'''\n",
        "  for box in output[0]:\n",
        "    ymin = int(box[0]*height)\n",
        "    xmin = int(box[1]*width)\n",
        "    ymax = int(box[2]*height)\n",
        "    xmax = int(box[3]*width) \n",
        "\n",
        "    box_new = []\n",
        "    box_new.append(xmin)\n",
        "    box_new.append(ymin)\n",
        "    box_new.append(xmax-xmin)\n",
        "    box_new.append(ymax-ymin)\n",
        "  \n",
        "\n",
        "    boxes2.append(box_new)\n",
        "  \n",
        "  \n",
        "  result.extend(\n",
        "        [\n",
        "            {\n",
        "                \"image_id\": converted_num,\n",
        "                \"category_id\": int(output[2][k]),\n",
        "                \"bbox\": box,\n",
        "                \"score\": output[1][k].astype(float),\n",
        "            }\n",
        "            for k, box in enumerate(boxes2)\n",
        "        ]\n",
        "  )\n",
        "\n",
        "  result2.extend(\n",
        "        [\n",
        "            {\n",
        "                \"image_id\": converted_num,\n",
        "                \"category_id\": int(output[2][k]),\n",
        "                \"bbox\": box,\n",
        "                \"score\": output[1][k].astype(float),\n",
        "            }\n",
        "            for k, box in enumerate(boxes2)\n",
        "        ]\n",
        "  )\n",
        "\n",
        "\n",
        "  for save_file in result2:    \n",
        "        out2.append(save_file)\n",
        "        \n",
        "  json_file = PATH_EVAL+MODEL+'/JSON/'+str(converted_num)+'.json'\n",
        "  with open(json_file, 'w', encoding='utf-8') as save_files:\n",
        "    json.dump(out2, save_files, ensure_ascii=False)\n",
        "        \n",
        "  for sample in result:    \n",
        "        out.append(sample)\n",
        "\n",
        "\n",
        "with open(PATH_EVAL+MODEL+'/'+'test_data_modificado.json', 'w', encoding='utf-8') as file:\n",
        "  json.dump(out, file, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df48a58c",
      "metadata": {
        "id": "df48a58c"
      },
      "outputs": [],
      "source": [
        "# pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "\n",
        "annType = ['segm','bbox','keypoints']\n",
        "annType = annType[1]      #specify type here\n",
        "prefix = 'person_keypoints' if annType=='keypoints' else 'instances'\n",
        "print ('Running demo for *%s* results.'%(annType))\n",
        "\n",
        "'''LOAD THE JSON WITH THE GROUND TRUTH (GT)'''\n",
        "annFile = ''\n",
        "cocoGt=COCO(annFile)\n",
        "\n",
        "'''LOAD THE JSON GENERATE IN THE PREVIOUS STEP'''\n",
        "resFile = ''\n",
        "\n",
        "cocoDt=cocoGt.loadRes(resFile)\n",
        "dts = json.load(open(resFile,'r'))\n",
        "imgIds = [imid['image_id'] for imid in dts]\n",
        "imgIds = sorted(list(set(imgIds)))\n",
        "\n",
        "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
        "cocoEval.params.imgIds  = imgIds\n",
        "\n",
        "'''PLEASE INSERT THE CLASS THAT YOU WANT TO EVALAUTE'''\n",
        "cocoEval.params.catIds = [3] \n",
        "cocoEval.evaluate()\n",
        "cocoEval.accumulate()\n",
        "cocoEval.summarize()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "DEMO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}